{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T13:50:52.518506Z",
     "start_time": "2026-02-11T13:50:52.105492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "from gitdb.fun import chunk_size\n",
    "\n",
    "\n",
    "def extract_all_from_pdf(pdf_path, output_dir=\"./extracted_data\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    all_content = {\"texts\": [], \"tables\": [], \"images\": []}\n",
    "\n",
    "    # 1. PyMuPDF(fitz)로 텍스트와 이미지 추출\n",
    "    doc = fitz.open(pdf_path)\n",
    "    # 2. pdfplumber로 테이블 추출 (레이아웃 보존 능력이 뛰어남)\n",
    "    pdf_plumber = pdfplumber.open(pdf_path)\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        print(f\"--- {page_num + 1} 페이지 처리 중 ---\")\n",
    "\n",
    "        # [텍스트 추출]\n",
    "        page = doc.load_page(page_num)\n",
    "        all_content[\"texts\"].append(page.get_text())\n",
    "\n",
    "        # [테이블 추출]\n",
    "        plumber_page = pdf_plumber.pages[page_num]\n",
    "        table = plumber_page.extract_table()\n",
    "        if table:\n",
    "            all_content[\"tables\"].append(table)\n",
    "\n",
    "        # [이미지 추출]\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "\n",
    "            img_filename = f\"page{page_num+1}_img{img_index+1}.{image_ext}\"\n",
    "            with open(os.path.join(output_dir, img_filename), \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "            all_content[\"images\"].append(img_filename)\n",
    "\n",
    "    doc.close()\n",
    "    pdf_plumber.close()\n",
    "    return all_content\n",
    "\n",
    "# 실행\n",
    "content = extract_all_from_pdf(\"invest/invest.pdf\")\n",
    "print(f\"\\n추출 완료: 텍스트 {len(content['texts'])}개, 테이블 {len(content['tables'])}개, 이미지 {len(content['images'])}개\")"
   ],
   "id": "f3f8c767a911a2b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1 페이지 처리 중 ---\n",
      "--- 2 페이지 처리 중 ---\n",
      "--- 3 페이지 처리 중 ---\n",
      "\n",
      "추출 완료: 텍스트 3개, 테이블 0개, 이미지 6개\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T13:50:52.530575Z",
     "start_time": "2026-02-11T13:50:52.526015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "fname = \"invest.pdf\"\n",
    "fpath = os.path.join(os.path.dirname(current_directory), \"ch14/invest/\")\n",
    "\n",
    "print(\"현재 스크립트의 위치:\", current_directory)\n",
    "print(\"pdf 위치:\",fpath)"
   ],
   "id": "59b96ceb6f828e60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 스크립트의 위치: /Users/kks/Desktop/Laboratory/jocoding_langchain/ch14\n",
      "pdf 위치: /Users/kks/Desktop/Laboratory/jocoding_langchain/ch14/invest/\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T13:50:52.559332Z",
     "start_time": "2026-02-11T13:50:52.554798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def categorize_elements(raw_pdf_elements: list):\n",
    "    \"\"\"\n",
    "    추출된 요소 리스트를 텍스트와 테이블로 분류합니다.\n",
    "\n",
    "    :param raw_pdf_elements: 텍스트와 테이블(마크다운)이 섞인 리스트\n",
    "    :return: (texts 리스트, tables 리스트) 튜플\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    tables = []\n",
    "    for element in raw_pdf_elements:\n",
    "        # Markdown 테이블 형식인지 간단히 확인 ( '|' 문자로 시작하고 끝나는지)\n",
    "        # Markdown 테이블은 헤더와 구분선이 필수적으로 포함되므로 이를 기준으로 판단\n",
    "        if isinstance(element, str) and element.strip().startswith(\"|\") and \"---\" in element:\n",
    "            tables.append(element)\n",
    "        else:\n",
    "            texts.append(element)\n",
    "    return texts, tables"
   ],
   "id": "b02b44887487fd77",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T13:50:52.858917Z",
     "start_time": "2026-02-11T13:50:52.575682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_pdf_elements = extract_all_from_pdf(fpath+fname)\n",
    "\n",
    "texts, tables = categorize_elements(raw_pdf_elements)\n"
   ],
   "id": "b8a3c763e22f272e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1 페이지 처리 중 ---\n",
      "--- 2 페이지 처리 중 ---\n",
      "--- 3 페이지 처리 중 ---\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T13:50:52.875347Z",
     "start_time": "2026-02-11T13:50:52.866690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=2000, chunk_overlap=200)\n",
    "\n",
    "joined_texts  = \" \".join(texts)\n",
    "texts_2k_token = text_splitter.split_text(joined_texts)\n",
    "\n",
    "print(len(texts_2k_token))\n",
    "print(len(texts))"
   ],
   "id": "c25d0141df6231ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T13:50:52.910342Z",
     "start_time": "2026-02-11T13:50:52.899246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI API 키가 없습니다. 한번 더 확인 부탁드립니다\")\n",
    "\n"
   ],
   "id": "2fbd37198b6c2e95",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T13:50:52.919811Z",
     "start_time": "2026-02-11T13:50:52.917980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n"
   ],
   "id": "a2a27d606c788e58",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T13:57:42.589929Z",
     "start_time": "2026-02-11T13:57:40.157368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 텍스트 요소의 요약 생성\n",
    "def generate_text_summaries(texts, tables, summarize_texts=False):\n",
    "    \"\"\"\n",
    "    텍스트 요소 요약 생성\n",
    "    texts: str 리스트\n",
    "    tables: str 리스트\n",
    "    summarize_texts: 텍스트 요약 여부를 나타내는 부울 값\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt 영어 버전\n",
    "    # prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    # These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    # Give a concise summary of the table or text that is well optimized for retrieval. Table or text: {element} \"\"\"\n",
    "\n",
    "    # Prompt 한국어 버전\n",
    "    prompt_text_kor = \"\"\"당신은 표와 텍스트를 요약하여 검색에 활용할 수 있도록 돕는 도우미입니다. \\n\n",
    "    이 요약본들은 임베딩되어 원본 텍스트나 표 요소를 검색하는 데 사용될 것입니다. \\n\n",
    "    주어진 표나 텍스트의 내용을 검색에 최적화된 간결한 요약으로 작성해 주세요. 요약할 표 또는 텍스트: {element}\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_text_kor)\n",
    "\n",
    "    # 텍스트 요약 체인 설정\n",
    "    # 모델: GPT-4o-mini or Llama3.1 모델 사용\n",
    "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    # llamaModel = OllamaLLM(model=\"llama3.1:8b\")\n",
    "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "    # 요약 결과를 저장할 빈 리스트 초기화\n",
    "    text_summaries = []\n",
    "    table_summaries = []\n",
    "\n",
    "    # 텍스트가 주어졌고 요약이 요청된 경우 요약을 적용\n",
    "    if texts and summarize_texts:\n",
    "        text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 5})\n",
    "    elif texts:\n",
    "        # 요약을 하지 않는 경우 원본 텍스트를 그대로 사용\n",
    "        text_summaries = texts\n",
    "\n",
    "    # 테이블이 주어졌을 경우 테이블에 대해 요약 적용\n",
    "    if tables:\n",
    "        table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
    "\n",
    "    return text_summaries, table_summaries\n",
    "\n",
    "\n",
    "# 텍스트와 테이블 요약 생성\n",
    "text_summaries, table_summaries = generate_text_summaries(\n",
    "    texts_2k_token, tables, summarize_texts=True\n",
    ")"
   ],
   "id": "305a406a4c8c23fc",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T13:50:55.064239Z",
     "start_time": "2026-02-11T13:50:55.062622Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "35cec16d4b8403fc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
